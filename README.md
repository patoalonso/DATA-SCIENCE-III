# NLP + Deep Learning en sinopsis de Goodreads

**Autora:** Alonso Castillo Patricia  
**ComisiÃ³n:** 67400

Proyecto de fin de cursada: clasificaciÃ³n binaria de â€œsentimientoâ€ de libros a partir de sus **sinopsis** (`book_details`). Usamos `average_rating` como seÃ±al (â‰¥ 4 â†’ positivo), un pipeline NLP de preprocesamiento y un clasificador **MLP** (baseline y versiÃ³n regularizada mejorada).

---

## ğŸ“¦ Dataset

- **Fuente:** [Books Dataset â€” Goodreads (May 2024)](https://www.kaggle.com/datasets/dk123891/books-dataset-goodreadsmay-2024)  
- **TamaÃ±o:** ~16k libros, ~15 columnas (tÃ­tulo, autor, gÃ©neros, `book_details`, `average_rating`, `num_reviews`, `num_ratings`, etc.).  
- En este trabajo se usa principalmente **`book_details`** (texto libre) y **`average_rating`** (para construir el target).

---

## ğŸ¯ Objetivo

Construir un clasificador binario que prediga **sentimiento**:
- `1` si `average_rating â‰¥ 4.0` (positivo)
- `0` si `average_rating < 4.0`

---

## ğŸ§ª MetodologÃ­a (resumen)

1. **EDA:** distribuciÃ³n de `average_rating`, gÃ©neros mÃ¡s frecuentes, relaciÃ³n `num_ratings`â€“`num_reviews` (logâ€“log), mÃ©tricas lÃ©xicas del corpus (TTR, hapax, % stopwords).
2. **Preprocesamiento NLP:**  
   - minÃºsculas + limpieza de puntuaciÃ³n (conservando apÃ³strofes),  
   - **stopwords** en inglÃ©s (se preservan negaciones),  
   - **lemmatizaciÃ³n con POS** (NLTK + WordNet).
3. **VectorizaciÃ³n:** **TF-IDF** con `max_features=5000`, `min_df=5`, `max_df=0.5`, `sublinear_tf=True`, `token_pattern='\\b[a-z]{3,}\\b'`.
4. **Split:** 80/20 estratificado (fit de TF-IDF **solo en train**).
5. **Modelos:**
   - **Baseline MLP:** `Dense(64, relu) â†’ Dense(1, sigmoid)`.
   - **Mejorado:** `Dense(128) â†’ Dropout â†’ Dense(64) â†’ Dropout â†’ Dense(1)` con **L2**, **Dropout**, **EarlyStopping**, **ReduceLROnPlateau**.
6. **Umbral de decisiÃ³n:** elegido en **validaciÃ³n** maximizando **macro-F1 / balanced accuracy** (sin usar test).
7. **EvaluaciÃ³n:** accuracy, macro-F1, balanced accuracy, matriz de confusiÃ³n.

---

## âœ… Resultados (test)

| Modelo                             | Accuracy | Macro-F1 | Balanced Acc. |
|-----------------------------------|:-------:|:--------:|:-------------:|
| **MLP baseline** (t = 0.50)       | 0.592   | 0.590    | 0.590         |
| **MLP mejorado** (t = 0.56, val)  | **0.610** | **0.610** | **0.613**     |

**ConclusiÃ³n breve:** la versiÃ³n regularizada + selecciÃ³n de umbral en validaciÃ³n **equilibra mejor las clases** y mejora todas las mÃ©tricas frente a la lÃ­nea base.

---

## ğŸ—‚ï¸ Estructura sugerida del repo

